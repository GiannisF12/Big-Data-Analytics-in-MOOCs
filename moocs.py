# -*- coding: utf-8 -*-
"""moocs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DK4-7ucTnjFdIIYspMzi8ajeSySzKKnn
"""

from google.colab import files
uploaded = files.upload()
data = pd.read_csv('CourseraDataset-Clean.csv')
data.head()

import pandas as pd
from sklearn.model_selection import train_test_split

# Φόρτωση δεδομένων
data = pd.read_csv('CourseraDataset-Clean.csv')

# Καθαρισμός δεδομένων - Αφαίρεση μαθημάτων χωρίς αξιολόγηση
clean_data = data[data['Rating'] > 0]

# Επιλογή χαρακτηριστικών
X = clean_data[['Duration to complete (Approx.)', 'Number of Review']]
y = clean_data['Rating']

# Διαχωρισμός δεδομένων σε training και testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Αρχικοποίηση μοντέλων
random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
linear_regression_model = LinearRegression()
gradient_boosting_model = GradientBoostingRegressor(random_state=42)

# Εκπαίδευση των μοντέλων
random_forest_model.fit(X_train, y_train)
linear_regression_model.fit(X_train, y_train)
gradient_boosting_model.fit(X_train, y_train)

# Πρόβλεψη
rf_predictions = random_forest_model.predict(X_test)
lr_predictions = linear_regression_model.predict(X_test)
gb_predictions = gradient_boosting_model.predict(X_test)

# Υπολογισμός MSE και R² Score
rf_mse = mean_squared_error(y_test, rf_predictions)
lr_mse = mean_squared_error(y_test, lr_predictions)
gb_mse = mean_squared_error(y_test, gb_predictions)

rf_r2 = r2_score(y_test, rf_predictions)
lr_r2 = r2_score(y_test, lr_predictions)
gb_r2 = r2_score(y_test, gb_predictions)

# Αποτελέσματα
results = pd.DataFrame({
    'Model': ['Random Forest', 'Linear Regression', 'Gradient Boosting'],
    'MSE': [rf_mse, lr_mse, gb_mse],
    'R² Score': [rf_r2, lr_r2, gb_r2]
})

print(results)

from google.colab import files
uploaded = files.upload()
data = pd.read_csv('CourseraDataset-Clean.csv')
data.head()

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, accuracy_score, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt


# Data cleaning and preparation
clean_data = data[data['Rating'] > 0]
X = clean_data[['Duration to complete (Approx.)', 'Number of Review']]
y = clean_data['Rating']
threshold = 4.5
y_class = np.where(y >= threshold, 1, 0)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_class, test_size=0.2, random_state=42)

# Initialize models
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
gb_classifier = GradientBoostingClassifier(random_state=42)
logistic_classifier = LogisticRegression(max_iter=1000, random_state=42)

# Train models
rf_classifier.fit(X_train, y_train)
gb_classifier.fit(X_train, y_train)
logistic_classifier.fit(X_train, y_train)

# Predictions and probabilities
rf_probs = rf_classifier.predict_proba(X_test)[:, 1]
gb_probs = gb_classifier.predict_proba(X_test)[:, 1]
logistic_probs = logistic_classifier.predict_proba(X_test)[:, 1]

rf_preds = rf_classifier.predict(X_test)
gb_preds = gb_classifier.predict(X_test)
logistic_preds = logistic_classifier.predict(X_test)

# Compute classification metrics
metrics = {
    'Model': ['Random Forest', 'Gradient Boosting', 'Logistic Regression'],
    'Accuracy': [
        accuracy_score(y_test, rf_preds),
        accuracy_score(y_test, gb_preds),
        accuracy_score(y_test, logistic_preds)
    ],
    'F1 Score': [
        f1_score(y_test, rf_preds),
        f1_score(y_test, gb_preds),
        f1_score(y_test, logistic_preds)
    ],
    'Precision': [
        precision_score(y_test, rf_preds),
        precision_score(y_test, gb_preds),
        precision_score(y_test, logistic_preds)
    ],
    'AUC': [
        roc_auc_score(y_test, rf_probs),
        roc_auc_score(y_test, gb_probs),
        roc_auc_score(y_test, logistic_probs)
    ]
}

metrics_df = pd.DataFrame(metrics)
print(metrics_df)

import matplotlib.pyplot as plt
import numpy as np

# Διάγραμμα σύγκρισης των MSE και R² Score
plt.figure(figsize=(10, 5))

# Διάγραμμα MSE
plt.subplot(1, 2, 1)
models = ['Random Forest', 'Linear Regression', 'Gradient Boosting']
mse_values = [rf_mse, lr_mse, gb_mse]
plt.bar(models, mse_values, color=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Comparison of MSE')
plt.ylabel('MSE')

# Διάγραμμα R² Score
plt.subplot(1, 2, 2)
r2_values = [rf_r2, lr_r2, gb_r2]
plt.bar(models, r2_values, color=['skyblue', 'lightgreen', 'lightcoral'])
plt.title('Comparison of R² Score')
plt.ylabel('R² Score')

plt.tight_layout()
plt.show()

# Διάγραμμα προβλέψεων vs πραγματικές τιμές για το Random Forest
plt.figure(figsize=(7, 5))
plt.scatter(y_test, rf_predictions, color='blue', label='Predictions')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Perfect Prediction Line')
plt.title('Random Forest: Predictions vs Real Values')
plt.xlabel('Real Values')
plt.ylabel('Predictions')
plt.legend()
plt.show()

# Compute ROC curves
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)
gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_probs)
logistic_fpr, logistic_tpr, _ = roc_curve(y_test, logistic_probs)

# Plot ROC curves
plt.figure(figsize=(10, 7))
plt.plot(rf_fpr, rf_tpr, label=f"Random Forest (AUC = {metrics_df.loc[0, 'AUC']:.2f})", color='blue')
plt.plot(gb_fpr, gb_tpr, label=f"Gradient Boosting (AUC = {metrics_df.loc[1, 'AUC']:.2f})", color='green')
plt.plot(logistic_fpr, logistic_tpr, label=f"Logistic Regression (AUC = {metrics_df.loc[2, 'AUC']:.2f})", color='red')

# Plot the No Skill line
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='No Skill')

# Customize plot
plt.title('ROC Curves for Classifiers')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()